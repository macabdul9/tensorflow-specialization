{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LR-using-TF",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcZfIbaq7ete",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0giufREMaRs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import load_boston"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoHfgoIyMmhD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "boston = load_boston()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXxv9ds9MyVB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features = boston.data\n",
        "labels = boston.target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gy0BdL2FNOuy",
        "colab_type": "code",
        "outputId": "3dd48180-9c46-4f9f-fd88-1f60230a7837",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(features.shape, labels.shape)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(506, 13) (506,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2_8WBqiNUSh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = np.reshape(labels, (-1, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcpsvfPHNz7D",
        "colab_type": "code",
        "outputId": "45e0adea-9680-4e8d-8b94-ea393be553a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(features.shape, labels.shape)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(506, 13) (506, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43tXvtGNN3OI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# normalize the data\n",
        "def normalize(data):\n",
        "  data = (data - np.mean(data))/np.std(data)\n",
        "  return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7xIu1MLONdD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "normalized_features = normalize(features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClVnwBX5OZva",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bias_features = np.ones((features.shape[0], 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mbk_rriSLn4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# concatenate the two\n",
        "normalized_features = np.hstack((bias_features, normalized_features))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PG-d-AUcSZ6F",
        "colab_type": "code",
        "outputId": "b36ee05b-4f47-4616-f970-370525fedb05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "normalized_features.shape"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(506, 14)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8TKZDGuSbTv",
        "colab_type": "code",
        "outputId": "19efa274-39d2-4d09-ecb4-7e0db2616af1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "normalized_features[:1]"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.        , -0.48270736, -0.35874599, -0.46683694, -0.4827509 ,\n",
              "        -0.47904453, -0.43745466, -0.03357755, -0.45457423, -0.47586174,\n",
              "         1.55644101, -0.37734672,  2.25155744, -0.44844287]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YY9a7XxSd8q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create mode\n",
        "n_features = normalized_features.shape[1]\n",
        "n_smaples = normalized_features.shape[0]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZnF67SITkJg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMvuXnrYT_B5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = tf.placeholder(dtype=tf.float32, shape=[None, n_features])\n",
        "Y = tf.placeholder(dtype=tf.float32, shape=[None, 1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yJMLp5kULcc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "W = tf.Variable(tf.random_normal(shape=(n_features, 1)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrT4xYC2VdUV",
        "colab_type": "code",
        "outputId": "fec65b21-c31b-495c-8b52-64ac5aaf8678",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "W.value"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method RefVariable.value of <tf.Variable 'Variable_1:0' shape=(14, 1) dtype=float32_ref>>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ivg_BItHVd4H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split the training and validation\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ueeGkMyn6vf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FfTsJ8RoDIQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(normalized_features, labels, test_size = 0.3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnQgiHBHoXPV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = tf.matmul(X, W)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJPn7iXj4Z9d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# loss\n",
        "\n",
        "cost = tf.reduce_mean( tf.square( y_pred - Y ) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOFqkuXj4qzR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AH_I7StN45kK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "49faf7a2-b596-4a8c-c6b9-a05fea00f279"
      },
      "source": [
        "with tf.Session() as sess:\n",
        "    ## Imp step\n",
        "    sess.run( tf.global_variables_initializer() )\n",
        "    \n",
        "    for epoch in range(100):\n",
        "        \n",
        "        sess.run( opt, feed_dict = {\n",
        "            X: x_train,\n",
        "            Y: y_train\n",
        "        } )\n",
        "        \n",
        "        train_loss = sess.run( cost, feed_dict = {\n",
        "            X: x_train,\n",
        "            Y: y_train\n",
        "        } )\n",
        "        \n",
        "        test_loss = sess.run( cost, feed_dict = {\n",
        "            X: x_test,\n",
        "            Y: y_test\n",
        "        } )\n",
        "        \n",
        "        print ( \"Epoch {}\\n\".format(epoch + 1) )\n",
        "        print (\"Training loss is {:.04f} and Testing loss is {:.04f}\".format( train_loss, test_loss ))\n",
        "        print (\"---------\")"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "\n",
            "Training loss is 451.1399 and Testing loss is 535.7725\n",
            "---------\n",
            "Epoch 2\n",
            "\n",
            "Training loss is 301.2481 and Testing loss is 375.1979\n",
            "---------\n",
            "Epoch 3\n",
            "\n",
            "Training loss is 217.6841 and Testing loss is 282.1697\n",
            "---------\n",
            "Epoch 4\n",
            "\n",
            "Training loss is 170.7115 and Testing loss is 227.2946\n",
            "---------\n",
            "Epoch 5\n",
            "\n",
            "Training loss is 143.9428 and Testing loss is 194.1416\n",
            "---------\n",
            "Epoch 6\n",
            "\n",
            "Training loss is 128.3464 and Testing loss is 173.4837\n",
            "---------\n",
            "Epoch 7\n",
            "\n",
            "Training loss is 118.9438 and Testing loss is 160.1082\n",
            "---------\n",
            "Epoch 8\n",
            "\n",
            "Training loss is 112.9901 and Testing loss is 151.0480\n",
            "---------\n",
            "Epoch 9\n",
            "\n",
            "Training loss is 108.9710 and Testing loss is 144.5978\n",
            "---------\n",
            "Epoch 10\n",
            "\n",
            "Training loss is 106.0508 and Testing loss is 139.7657\n",
            "---------\n",
            "Epoch 11\n",
            "\n",
            "Training loss is 103.7672 and Testing loss is 135.9662\n",
            "---------\n",
            "Epoch 12\n",
            "\n",
            "Training loss is 101.8642 and Testing loss is 132.8475\n",
            "---------\n",
            "Epoch 13\n",
            "\n",
            "Training loss is 100.1995 and Testing loss is 130.1943\n",
            "---------\n",
            "Epoch 14\n",
            "\n",
            "Training loss is 98.6932 and Testing loss is 127.8712\n",
            "---------\n",
            "Epoch 15\n",
            "\n",
            "Training loss is 97.3001 and Testing loss is 125.7915\n",
            "---------\n",
            "Epoch 16\n",
            "\n",
            "Training loss is 95.9942 and Testing loss is 123.8978\n",
            "---------\n",
            "Epoch 17\n",
            "\n",
            "Training loss is 94.7599 and Testing loss is 122.1512\n",
            "---------\n",
            "Epoch 18\n",
            "\n",
            "Training loss is 93.5877 and Testing loss is 120.5248\n",
            "---------\n",
            "Epoch 19\n",
            "\n",
            "Training loss is 92.4711 and Testing loss is 118.9992\n",
            "---------\n",
            "Epoch 20\n",
            "\n",
            "Training loss is 91.4058 and Testing loss is 117.5602\n",
            "---------\n",
            "Epoch 21\n",
            "\n",
            "Training loss is 90.3884 and Testing loss is 116.1972\n",
            "---------\n",
            "Epoch 22\n",
            "\n",
            "Training loss is 89.4160 and Testing loss is 114.9021\n",
            "---------\n",
            "Epoch 23\n",
            "\n",
            "Training loss is 88.4864 and Testing loss is 113.6683\n",
            "---------\n",
            "Epoch 24\n",
            "\n",
            "Training loss is 87.5974 and Testing loss is 112.4908\n",
            "---------\n",
            "Epoch 25\n",
            "\n",
            "Training loss is 86.7470 and Testing loss is 111.3652\n",
            "---------\n",
            "Epoch 26\n",
            "\n",
            "Training loss is 85.9335 and Testing loss is 110.2880\n",
            "---------\n",
            "Epoch 27\n",
            "\n",
            "Training loss is 85.1552 and Testing loss is 109.2561\n",
            "---------\n",
            "Epoch 28\n",
            "\n",
            "Training loss is 84.4104 and Testing loss is 108.2668\n",
            "---------\n",
            "Epoch 29\n",
            "\n",
            "Training loss is 83.6976 and Testing loss is 107.3179\n",
            "---------\n",
            "Epoch 30\n",
            "\n",
            "Training loss is 83.0153 and Testing loss is 106.4071\n",
            "---------\n",
            "Epoch 31\n",
            "\n",
            "Training loss is 82.3622 and Testing loss is 105.5325\n",
            "---------\n",
            "Epoch 32\n",
            "\n",
            "Training loss is 81.7369 and Testing loss is 104.6924\n",
            "---------\n",
            "Epoch 33\n",
            "\n",
            "Training loss is 81.1383 and Testing loss is 103.8851\n",
            "---------\n",
            "Epoch 34\n",
            "\n",
            "Training loss is 80.5649 and Testing loss is 103.1091\n",
            "---------\n",
            "Epoch 35\n",
            "\n",
            "Training loss is 80.0158 and Testing loss is 102.3630\n",
            "---------\n",
            "Epoch 36\n",
            "\n",
            "Training loss is 79.4899 and Testing loss is 101.6455\n",
            "---------\n",
            "Epoch 37\n",
            "\n",
            "Training loss is 78.9860 and Testing loss is 100.9553\n",
            "---------\n",
            "Epoch 38\n",
            "\n",
            "Training loss is 78.5031 and Testing loss is 100.2912\n",
            "---------\n",
            "Epoch 39\n",
            "\n",
            "Training loss is 78.0404 and Testing loss is 99.6521\n",
            "---------\n",
            "Epoch 40\n",
            "\n",
            "Training loss is 77.5969 and Testing loss is 99.0368\n",
            "---------\n",
            "Epoch 41\n",
            "\n",
            "Training loss is 77.1717 and Testing loss is 98.4445\n",
            "---------\n",
            "Epoch 42\n",
            "\n",
            "Training loss is 76.7640 and Testing loss is 97.8740\n",
            "---------\n",
            "Epoch 43\n",
            "\n",
            "Training loss is 76.3731 and Testing loss is 97.3245\n",
            "---------\n",
            "Epoch 44\n",
            "\n",
            "Training loss is 75.9981 and Testing loss is 96.7950\n",
            "---------\n",
            "Epoch 45\n",
            "\n",
            "Training loss is 75.6384 and Testing loss is 96.2848\n",
            "---------\n",
            "Epoch 46\n",
            "\n",
            "Training loss is 75.2932 and Testing loss is 95.7930\n",
            "---------\n",
            "Epoch 47\n",
            "\n",
            "Training loss is 74.9619 and Testing loss is 95.3188\n",
            "---------\n",
            "Epoch 48\n",
            "\n",
            "Training loss is 74.6438 and Testing loss is 94.8615\n",
            "---------\n",
            "Epoch 49\n",
            "\n",
            "Training loss is 74.3384 and Testing loss is 94.4205\n",
            "---------\n",
            "Epoch 50\n",
            "\n",
            "Training loss is 74.0452 and Testing loss is 93.9949\n",
            "---------\n",
            "Epoch 51\n",
            "\n",
            "Training loss is 73.7634 and Testing loss is 93.5842\n",
            "---------\n",
            "Epoch 52\n",
            "\n",
            "Training loss is 73.4927 and Testing loss is 93.1878\n",
            "---------\n",
            "Epoch 53\n",
            "\n",
            "Training loss is 73.2326 and Testing loss is 92.8050\n",
            "---------\n",
            "Epoch 54\n",
            "\n",
            "Training loss is 72.9825 and Testing loss is 92.4354\n",
            "---------\n",
            "Epoch 55\n",
            "\n",
            "Training loss is 72.7420 and Testing loss is 92.0783\n",
            "---------\n",
            "Epoch 56\n",
            "\n",
            "Training loss is 72.5106 and Testing loss is 91.7332\n",
            "---------\n",
            "Epoch 57\n",
            "\n",
            "Training loss is 72.2881 and Testing loss is 91.3997\n",
            "---------\n",
            "Epoch 58\n",
            "\n",
            "Training loss is 72.0739 and Testing loss is 91.0773\n",
            "---------\n",
            "Epoch 59\n",
            "\n",
            "Training loss is 71.8677 and Testing loss is 90.7655\n",
            "---------\n",
            "Epoch 60\n",
            "\n",
            "Training loss is 71.6691 and Testing loss is 90.4640\n",
            "---------\n",
            "Epoch 61\n",
            "\n",
            "Training loss is 71.4778 and Testing loss is 90.1721\n",
            "---------\n",
            "Epoch 62\n",
            "\n",
            "Training loss is 71.2935 and Testing loss is 89.8897\n",
            "---------\n",
            "Epoch 63\n",
            "\n",
            "Training loss is 71.1158 and Testing loss is 89.6163\n",
            "---------\n",
            "Epoch 64\n",
            "\n",
            "Training loss is 70.9445 and Testing loss is 89.3515\n",
            "---------\n",
            "Epoch 65\n",
            "\n",
            "Training loss is 70.7793 and Testing loss is 89.0950\n",
            "---------\n",
            "Epoch 66\n",
            "\n",
            "Training loss is 70.6198 and Testing loss is 88.8465\n",
            "---------\n",
            "Epoch 67\n",
            "\n",
            "Training loss is 70.4659 and Testing loss is 88.6056\n",
            "---------\n",
            "Epoch 68\n",
            "\n",
            "Training loss is 70.3173 and Testing loss is 88.3721\n",
            "---------\n",
            "Epoch 69\n",
            "\n",
            "Training loss is 70.1738 and Testing loss is 88.1456\n",
            "---------\n",
            "Epoch 70\n",
            "\n",
            "Training loss is 70.0351 and Testing loss is 87.9259\n",
            "---------\n",
            "Epoch 71\n",
            "\n",
            "Training loss is 69.9010 and Testing loss is 87.7127\n",
            "---------\n",
            "Epoch 72\n",
            "\n",
            "Training loss is 69.7713 and Testing loss is 87.5057\n",
            "---------\n",
            "Epoch 73\n",
            "\n",
            "Training loss is 69.6458 and Testing loss is 87.3047\n",
            "---------\n",
            "Epoch 74\n",
            "\n",
            "Training loss is 69.5244 and Testing loss is 87.1095\n",
            "---------\n",
            "Epoch 75\n",
            "\n",
            "Training loss is 69.4068 and Testing loss is 86.9199\n",
            "---------\n",
            "Epoch 76\n",
            "\n",
            "Training loss is 69.2929 and Testing loss is 86.7355\n",
            "---------\n",
            "Epoch 77\n",
            "\n",
            "Training loss is 69.1826 and Testing loss is 86.5563\n",
            "---------\n",
            "Epoch 78\n",
            "\n",
            "Training loss is 69.0755 and Testing loss is 86.3820\n",
            "---------\n",
            "Epoch 79\n",
            "\n",
            "Training loss is 68.9717 and Testing loss is 86.2124\n",
            "---------\n",
            "Epoch 80\n",
            "\n",
            "Training loss is 68.8710 and Testing loss is 86.0474\n",
            "---------\n",
            "Epoch 81\n",
            "\n",
            "Training loss is 68.7732 and Testing loss is 85.8868\n",
            "---------\n",
            "Epoch 82\n",
            "\n",
            "Training loss is 68.6783 and Testing loss is 85.7304\n",
            "---------\n",
            "Epoch 83\n",
            "\n",
            "Training loss is 68.5860 and Testing loss is 85.5780\n",
            "---------\n",
            "Epoch 84\n",
            "\n",
            "Training loss is 68.4963 and Testing loss is 85.4295\n",
            "---------\n",
            "Epoch 85\n",
            "\n",
            "Training loss is 68.4090 and Testing loss is 85.2848\n",
            "---------\n",
            "Epoch 86\n",
            "\n",
            "Training loss is 68.3241 and Testing loss is 85.1437\n",
            "---------\n",
            "Epoch 87\n",
            "\n",
            "Training loss is 68.2415 and Testing loss is 85.0061\n",
            "---------\n",
            "Epoch 88\n",
            "\n",
            "Training loss is 68.1610 and Testing loss is 84.8718\n",
            "---------\n",
            "Epoch 89\n",
            "\n",
            "Training loss is 68.0826 and Testing loss is 84.7407\n",
            "---------\n",
            "Epoch 90\n",
            "\n",
            "Training loss is 68.0061 and Testing loss is 84.6127\n",
            "---------\n",
            "Epoch 91\n",
            "\n",
            "Training loss is 67.9315 and Testing loss is 84.4878\n",
            "---------\n",
            "Epoch 92\n",
            "\n",
            "Training loss is 67.8588 and Testing loss is 84.3657\n",
            "---------\n",
            "Epoch 93\n",
            "\n",
            "Training loss is 67.7877 and Testing loss is 84.2464\n",
            "---------\n",
            "Epoch 94\n",
            "\n",
            "Training loss is 67.7183 and Testing loss is 84.1298\n",
            "---------\n",
            "Epoch 95\n",
            "\n",
            "Training loss is 67.6505 and Testing loss is 84.0157\n",
            "---------\n",
            "Epoch 96\n",
            "\n",
            "Training loss is 67.5842 and Testing loss is 83.9042\n",
            "---------\n",
            "Epoch 97\n",
            "\n",
            "Training loss is 67.5194 and Testing loss is 83.7950\n",
            "---------\n",
            "Epoch 98\n",
            "\n",
            "Training loss is 67.4559 and Testing loss is 83.6882\n",
            "---------\n",
            "Epoch 99\n",
            "\n",
            "Training loss is 67.3939 and Testing loss is 83.5835\n",
            "---------\n",
            "Epoch 100\n",
            "\n",
            "Training loss is 67.3330 and Testing loss is 83.4811\n",
            "---------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoVh4M-N6_a5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}